{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2a3dd631d444cabaeb708cd41b84d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42967d93dc0047abbad9a0f97ff5e704",
              "IPY_MODEL_149b0659e81b47489b5dedffc79f6951",
              "IPY_MODEL_e61388e32bb143c8a8753404b461e557"
            ],
            "layout": "IPY_MODEL_c2ac9e9d4776424e92c661d811cabb5f"
          }
        },
        "42967d93dc0047abbad9a0f97ff5e704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2f1ed3d9a0c40f296c40c53e05d6e2f",
            "placeholder": "​",
            "style": "IPY_MODEL_6287db71e1f94a09bd5312510bf52f9f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "149b0659e81b47489b5dedffc79f6951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c3795dd07d4bdabca0142c34c5c86e",
            "max": 1293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37b55c52c9954819bd62a5b200cdbbf5",
            "value": 1293
          }
        },
        "e61388e32bb143c8a8753404b461e557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de721a9e13a84a81911b3210339840ab",
            "placeholder": "​",
            "style": "IPY_MODEL_a2847ffa575144e1947b53a6dd6d4b32",
            "value": " 1.29k/1.29k [00:00&lt;00:00, 45.5kB/s]"
          }
        },
        "c2ac9e9d4776424e92c661d811cabb5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f1ed3d9a0c40f296c40c53e05d6e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6287db71e1f94a09bd5312510bf52f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03c3795dd07d4bdabca0142c34c5c86e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b55c52c9954819bd62a5b200cdbbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de721a9e13a84a81911b3210339840ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2847ffa575144e1947b53a6dd6d4b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a42e5794da24ed2840edb61b06d899e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a071d089233452eb622428f88416cd5",
              "IPY_MODEL_eb03d173ef8946a1a0060e873bc19a6f",
              "IPY_MODEL_376ba9005f524cb3850327ac990e12e9"
            ],
            "layout": "IPY_MODEL_9e3392b22db74daaab38befe063e2d3e"
          }
        },
        "1a071d089233452eb622428f88416cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb9e52b745b14e90a346b1050caa9de1",
            "placeholder": "​",
            "style": "IPY_MODEL_1d97ce3e96194e4e885ad46db1eac3d2",
            "value": "vocab.txt: 100%"
          }
        },
        "eb03d173ef8946a1a0060e873bc19a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b92006eb8f5848ca8622a89ab9828e43",
            "max": 1164495,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f78f629fe904caf8e5ec66ee87dbe7f",
            "value": 1164495
          }
        },
        "376ba9005f524cb3850327ac990e12e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ec8fd0bac24adab84d91cec94dc396",
            "placeholder": "​",
            "style": "IPY_MODEL_5749ec6f0c4948fca758d3c665099119",
            "value": " 1.16M/1.16M [00:00&lt;00:00, 2.86MB/s]"
          }
        },
        "9e3392b22db74daaab38befe063e2d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9e52b745b14e90a346b1050caa9de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d97ce3e96194e4e885ad46db1eac3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b92006eb8f5848ca8622a89ab9828e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f78f629fe904caf8e5ec66ee87dbe7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97ec8fd0bac24adab84d91cec94dc396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5749ec6f0c4948fca758d3c665099119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef5b6d82c5f34efbbe49dfde52406515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af5bcbdbeac24cd0b545cf0c53cf5084",
              "IPY_MODEL_dca24ade5703494196874ebe1d97f4a3",
              "IPY_MODEL_da0e6b34a8264696b26f7adc03168ca8"
            ],
            "layout": "IPY_MODEL_e4d412202f9544529b85c18ffe43505f"
          }
        },
        "af5bcbdbeac24cd0b545cf0c53cf5084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_657389f8ae764643b6d0fb047082d99f",
            "placeholder": "​",
            "style": "IPY_MODEL_9ce800682b5a45a19c27314271c97da1",
            "value": "tokenizer.json: 100%"
          }
        },
        "dca24ade5703494196874ebe1d97f4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219a17565e3c4a8388468d3ff688e74f",
            "max": 2413691,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bb0019e707b45b0823db520822640c1",
            "value": 2413691
          }
        },
        "da0e6b34a8264696b26f7adc03168ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab2d7dec23e747d2ac2ad6412f366e7c",
            "placeholder": "​",
            "style": "IPY_MODEL_a479101d07cf4140b0c5db148ad7ad99",
            "value": " 2.41M/2.41M [00:00&lt;00:00, 27.5MB/s]"
          }
        },
        "e4d412202f9544529b85c18ffe43505f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657389f8ae764643b6d0fb047082d99f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce800682b5a45a19c27314271c97da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "219a17565e3c4a8388468d3ff688e74f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bb0019e707b45b0823db520822640c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab2d7dec23e747d2ac2ad6412f366e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a479101d07cf4140b0c5db148ad7ad99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e55ff3dfb4a4ba5b08294aca52e175c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2df48f3de13c413dbaf305f97610be86",
              "IPY_MODEL_08d51017a6464561a3ee38783f1b9f9b",
              "IPY_MODEL_429b9166f5b44b7f90b8a94ae63ffec4"
            ],
            "layout": "IPY_MODEL_16e6f8cf3ce24c4981c530cd325d23d3"
          }
        },
        "2df48f3de13c413dbaf305f97610be86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff8d1788da754531968da3d1f92e6fff",
            "placeholder": "​",
            "style": "IPY_MODEL_d4393c1fa3c74d01a5b3a3384a1c3e45",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "08d51017a6464561a3ee38783f1b9f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b64b2eb3f5bf40baa19915ca7d30c173",
            "max": 732,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e59bfce7b4140e383f2c05dccb637db",
            "value": 732
          }
        },
        "429b9166f5b44b7f90b8a94ae63ffec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98d83276a1124f29800c60f7f60b2628",
            "placeholder": "​",
            "style": "IPY_MODEL_a63949daa74341faaa304454ac182c78",
            "value": " 732/732 [00:00&lt;00:00, 40.5kB/s]"
          }
        },
        "16e6f8cf3ce24c4981c530cd325d23d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff8d1788da754531968da3d1f92e6fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4393c1fa3c74d01a5b3a3384a1c3e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b64b2eb3f5bf40baa19915ca7d30c173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e59bfce7b4140e383f2c05dccb637db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98d83276a1124f29800c60f7f60b2628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63949daa74341faaa304454ac182c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1b7d3a2218941f6b338ee4c251c339c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f483e41b87a14b069175e54084155cce",
              "IPY_MODEL_83c6497ef7f2426f91d055933b9fc057",
              "IPY_MODEL_561e1f600dde447789b0a1872b918ab6"
            ],
            "layout": "IPY_MODEL_2f7bef73a3374b318acb45895d309f04"
          }
        },
        "f483e41b87a14b069175e54084155cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ddad3c344ac4fddad82b5750821589f",
            "placeholder": "​",
            "style": "IPY_MODEL_2b0a7d17a00f491a9893004c19611fa9",
            "value": "config.json: 100%"
          }
        },
        "83c6497ef7f2426f91d055933b9fc057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a7357cec82b4a44ac7ea15d214e242f",
            "max": 712,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07f1ba13ace2494fb180ae4de9634c2a",
            "value": 712
          }
        },
        "561e1f600dde447789b0a1872b918ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a348633d334847f4afbb337e939fdeb0",
            "placeholder": "​",
            "style": "IPY_MODEL_aaeab85b71d140999c3418605812155d",
            "value": " 712/712 [00:00&lt;00:00, 26.7kB/s]"
          }
        },
        "2f7bef73a3374b318acb45895d309f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ddad3c344ac4fddad82b5750821589f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0a7d17a00f491a9893004c19611fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a7357cec82b4a44ac7ea15d214e242f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f1ba13ace2494fb180ae4de9634c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a348633d334847f4afbb337e939fdeb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaeab85b71d140999c3418605812155d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "add29a12ba6446e89189e9a01de65be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e09b4b0f0114b94a2042194e6074cf4",
              "IPY_MODEL_b2382baefebd406182941aa0abc9a22b",
              "IPY_MODEL_566d69a1ba374e17a83c48817ed026c2"
            ],
            "layout": "IPY_MODEL_af8a67cd3b52467499a5cb59eeab005e"
          }
        },
        "0e09b4b0f0114b94a2042194e6074cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9a83fd29d7f477a8c4b597a8c274d95",
            "placeholder": "​",
            "style": "IPY_MODEL_c663c2983855429a814ee1fab1060a84",
            "value": "model.safetensors: 100%"
          }
        },
        "b2382baefebd406182941aa0abc9a22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42d5571886a5494fb941aebdf717f9eb",
            "max": 116781184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dd025e7c04a4738bf89ceeecfcf7b83",
            "value": 116781184
          }
        },
        "566d69a1ba374e17a83c48817ed026c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe105203e1764a43abf3b586cca0ba80",
            "placeholder": "​",
            "style": "IPY_MODEL_c69a31df6f6649f68780a89580951acb",
            "value": " 117M/117M [00:11&lt;00:00, 10.4MB/s]"
          }
        },
        "af8a67cd3b52467499a5cb59eeab005e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a83fd29d7f477a8c4b597a8c274d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c663c2983855429a814ee1fab1060a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42d5571886a5494fb941aebdf717f9eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dd025e7c04a4738bf89ceeecfcf7b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe105203e1764a43abf3b586cca0ba80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69a31df6f6649f68780a89580951acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U lightautoml"
      ],
      "metadata": {
        "id": "YQqIR8GZQ-Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "id": "8w3Pwm1RY_IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textstat"
      ],
      "metadata": {
        "id": "uMlQORSbsKo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9t8c9GRZHktD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8550dbed-a86b-4fd2-8a8a-997253ef99af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Работа с файловой системой и HTTP-запросами\n",
        "import os\n",
        "import requests\n",
        "\n",
        "# Библиотеки для работы с данными и моделями\n",
        "import numpy as np  # Массивы и математика\n",
        "import pandas as pd  # Работа с табличными данными\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report  # Метрики оценки моделей\n",
        "from sklearn.model_selection import train_test_split  # Разделение данных на обучающую и тестовую выборки\n",
        "from sklearn.preprocessing import LabelEncoder  # Кодирование категориальных признаков\n",
        "\n",
        "# Работа с нейронными сетями\n",
        "import torch  # Фреймворк для глубокого обучения\n",
        "from transformers import AutoTokenizer, AutoModel  # Токенизатор и модель из библиотеки Transformers\n",
        "\n",
        "# Работа с текстами\n",
        "import textstat  # Лингвистические метрики текстов\n",
        "import re  # Регулярные выражения\n",
        "\n",
        "# Прогресс-бар для циклов\n",
        "from tqdm import tqdm  # Удобный прогресс-бар\n",
        "\n",
        "# Работа с временем и датами\n",
        "from datetime import datetime  # Работа с временными метками\n",
        "\n",
        "# LightAutoML для автоматического машинного обучения\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML  # Предустановки моделей\n",
        "from lightautoml.tasks import Task  # Определение задачи (например, классификация, регрессия)\n",
        "from lightautoml.report.report_deco import ReportDeco, ReportDecoUtilized  # Генерация отчетов\n",
        "from lightautoml.addons.tabular_interpretation import SSWARM  # Интерпретация моделей\n",
        "\n",
        "# typing для аннотаций типов\n",
        "from typing import List  # Аннотация списка\n"
      ],
      "metadata": {
        "id": "3oePMdJXUUWT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация токенизатора и модели\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sergeyzh/rubert-tiny-turbo\")\n",
        "model = AutoModel.from_pretrained(\"sergeyzh/rubert-tiny-turbo\")\n",
        "\n",
        "# Функция для предобработки текста (пример реализации)\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    return text.lower()\n",
        "\n",
        "# Функция для извлечения первой даты из текста\n",
        "def extract_first_date(text):\n",
        "    if not isinstance(text, str):\n",
        "        return None\n",
        "\n",
        "    date_pattern = r'\\b\\d{1,2}[./-]\\d{1,2}[./-]\\d{2,4}\\b'\n",
        "    match = re.search(date_pattern, text)\n",
        "\n",
        "    if match:\n",
        "        date_str = match.group()\n",
        "        for fmt in (\"%d.%m.%Y\", \"%d/%m/%Y\", \"%d-%m-%Y\", \"%d.%m.%y\", \"%d/%m/%y\", \"%d-%m-%y\"):\n",
        "            try:\n",
        "                return datetime.strptime(date_str, fmt)\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "    return None\n",
        "\n",
        "# Функция для вычисления разницы в днях между двумя датами\n",
        "def calculate_days_difference(extracted_date, reference_date):\n",
        "    if pd.isna(extracted_date) or pd.isna(reference_date):\n",
        "        return None\n",
        "    return (reference_date - extracted_date).days\n",
        "\n",
        "# Функция для получения эмбеддингов из текста\n",
        "def get_embeddings(text: str):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "# Функция для генерации текстовых признаков с использованием textstat\n",
        "def get_textstat_features(text):\n",
        "    features = {}\n",
        "    if not isinstance(text, str):\n",
        "        return features\n",
        "    # Расчет признаков textstat\n",
        "    features['flesch_reading_ease'] = textstat.flesch_reading_ease(text)\n",
        "    features['smog_index'] = textstat.smog_index(text)\n",
        "    features['flesch_kincaid_grade'] = textstat.flesch_kincaid_grade(text)\n",
        "    features['coleman_liau_index'] = textstat.coleman_liau_index(text)\n",
        "    features['automated_readability_index'] = textstat.automated_readability_index(text)\n",
        "    features['dale_chall_readability_score'] = textstat.dale_chall_readability_score(text)\n",
        "    features['difficult_words'] = textstat.difficult_words(text)\n",
        "    features['linsear_write_formula'] = textstat.linsear_write_formula(text)\n",
        "    features['gunning_fog'] = textstat.gunning_fog(text)\n",
        "    features['text_standard'] = textstat.text_standard(text, float_output=True)\n",
        "    features['syllable_count'] = textstat.syllable_count(text)\n",
        "    features['lexicon_count'] = textstat.lexicon_count(text)\n",
        "    features['sentence_count'] = textstat.sentence_count(text)\n",
        "    return features\n",
        "\n",
        "# Функция для извлечения признаков из DataFrame\n",
        "def extract_features(df, text_column):\n",
        "    # Предобработка текста\n",
        "    df[text_column] = df[text_column].apply(preprocess_text)\n",
        "\n",
        "    # Извлечение номеров контрактов и их замена в тексте\n",
        "    def replace_contract_numbers(text):\n",
        "        if not isinstance(text, str):\n",
        "            return text, False\n",
        "        contract_pattern = r'(\\b\\d{2,}-\\d{4,}\\b)'\n",
        "        match = re.search(contract_pattern, text)\n",
        "        if match:\n",
        "            return re.sub(contract_pattern, '[CONTRACT_NUMBER]', text), True\n",
        "        return text, False\n",
        "\n",
        "    df[text_column], has_contract_number = zip(\n",
        "        *df[text_column].apply(replace_contract_numbers))\n",
        "\n",
        "    # Извлечение дат и их замена в тексте\n",
        "    def replace_dates_and_extract(text):\n",
        "        if not isinstance(text, str):\n",
        "            return text, None\n",
        "        date_pattern = r'\\b\\d{1,2}[./-]\\d{1,2}[./-]\\d{2,4}\\b'\n",
        "        match = re.search(date_pattern, text)\n",
        "        if match:\n",
        "            extracted_date = extract_first_date(match.group())\n",
        "            text = re.sub(date_pattern, '[DATE]', text)\n",
        "            return text, extracted_date\n",
        "        return text, None\n",
        "\n",
        "    df[text_column], extracted_dates = zip(\n",
        "        *df[text_column].apply(replace_dates_and_extract))\n",
        "\n",
        "    # Вычисление разницы в датах, если существует столбец 'Date'\n",
        "    if 'Date' in df.columns:\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "        df['date_difference'] = [\n",
        "            calculate_days_difference(extracted_date, reference_date)\n",
        "            for extracted_date, reference_date in zip(extracted_dates, df['Date'])\n",
        "        ]\n",
        "    else:\n",
        "        df['date_difference'] = None\n",
        "\n",
        "    # Получение эмбеддингов\n",
        "    embeddings = df[text_column].progress_apply(get_embeddings)\n",
        "\n",
        "    # Развертывание эмбеддингов в индивидуальные столбцы\n",
        "    embeddings_df = pd.DataFrame(embeddings.tolist(), index=df.index)\n",
        "    embeddings_df.columns = [f'embedding_{i}' for i in range(embeddings_df.shape[1])]\n",
        "\n",
        "    # Подсчет количества слов в тексте\n",
        "    word_count = df[text_column].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # Получение признаков textstat\n",
        "    textstat_features = df[text_column].apply(get_textstat_features)\n",
        "    textstat_df = pd.DataFrame(textstat_features.tolist())\n",
        "\n",
        "    # Объединение признаков обратно в исходный DataFrame\n",
        "    df = pd.concat([df.reset_index(drop=True), pd.DataFrame({\n",
        "        'has_contract_number': has_contract_number,\n",
        "        'word_count': word_count\n",
        "    }), embeddings_df.reset_index(drop=True), textstat_df.reset_index(drop=True)], axis=1)\n",
        "    df = df.drop(columns=[text_column])\n",
        "    return df\n",
        "\n",
        "# Функция для загрузки и предобработки данных\n",
        "def load_data(file_path, sep='\\t', header=None, names=None):\n",
        "    data = pd.read_csv(file_path, sep=sep, header=header, names=names)\n",
        "    if 'Date' in data.columns:\n",
        "        data['Date'] = pd.to_datetime(data['Date'], format='%d.%m.%Y')\n",
        "    data['Price'] = data['Price'].replace({',': '.', '-': '.'}, regex=True)\n",
        "    data['Price'] = pd.to_numeric(data['Price'], errors='coerce')\n",
        "    data['Price'] = data['Price'].apply(lambda x: float(x))\n",
        "    return data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "a2a3dd631d444cabaeb708cd41b84d8e",
            "42967d93dc0047abbad9a0f97ff5e704",
            "149b0659e81b47489b5dedffc79f6951",
            "e61388e32bb143c8a8753404b461e557",
            "c2ac9e9d4776424e92c661d811cabb5f",
            "d2f1ed3d9a0c40f296c40c53e05d6e2f",
            "6287db71e1f94a09bd5312510bf52f9f",
            "03c3795dd07d4bdabca0142c34c5c86e",
            "37b55c52c9954819bd62a5b200cdbbf5",
            "de721a9e13a84a81911b3210339840ab",
            "a2847ffa575144e1947b53a6dd6d4b32",
            "8a42e5794da24ed2840edb61b06d899e",
            "1a071d089233452eb622428f88416cd5",
            "eb03d173ef8946a1a0060e873bc19a6f",
            "376ba9005f524cb3850327ac990e12e9",
            "9e3392b22db74daaab38befe063e2d3e",
            "bb9e52b745b14e90a346b1050caa9de1",
            "1d97ce3e96194e4e885ad46db1eac3d2",
            "b92006eb8f5848ca8622a89ab9828e43",
            "2f78f629fe904caf8e5ec66ee87dbe7f",
            "97ec8fd0bac24adab84d91cec94dc396",
            "5749ec6f0c4948fca758d3c665099119",
            "ef5b6d82c5f34efbbe49dfde52406515",
            "af5bcbdbeac24cd0b545cf0c53cf5084",
            "dca24ade5703494196874ebe1d97f4a3",
            "da0e6b34a8264696b26f7adc03168ca8",
            "e4d412202f9544529b85c18ffe43505f",
            "657389f8ae764643b6d0fb047082d99f",
            "9ce800682b5a45a19c27314271c97da1",
            "219a17565e3c4a8388468d3ff688e74f",
            "3bb0019e707b45b0823db520822640c1",
            "ab2d7dec23e747d2ac2ad6412f366e7c",
            "a479101d07cf4140b0c5db148ad7ad99",
            "7e55ff3dfb4a4ba5b08294aca52e175c",
            "2df48f3de13c413dbaf305f97610be86",
            "08d51017a6464561a3ee38783f1b9f9b",
            "429b9166f5b44b7f90b8a94ae63ffec4",
            "16e6f8cf3ce24c4981c530cd325d23d3",
            "ff8d1788da754531968da3d1f92e6fff",
            "d4393c1fa3c74d01a5b3a3384a1c3e45",
            "b64b2eb3f5bf40baa19915ca7d30c173",
            "4e59bfce7b4140e383f2c05dccb637db",
            "98d83276a1124f29800c60f7f60b2628",
            "a63949daa74341faaa304454ac182c78",
            "b1b7d3a2218941f6b338ee4c251c339c",
            "f483e41b87a14b069175e54084155cce",
            "83c6497ef7f2426f91d055933b9fc057",
            "561e1f600dde447789b0a1872b918ab6",
            "2f7bef73a3374b318acb45895d309f04",
            "1ddad3c344ac4fddad82b5750821589f",
            "2b0a7d17a00f491a9893004c19611fa9",
            "2a7357cec82b4a44ac7ea15d214e242f",
            "07f1ba13ace2494fb180ae4de9634c2a",
            "a348633d334847f4afbb337e939fdeb0",
            "aaeab85b71d140999c3418605812155d",
            "add29a12ba6446e89189e9a01de65be8",
            "0e09b4b0f0114b94a2042194e6074cf4",
            "b2382baefebd406182941aa0abc9a22b",
            "566d69a1ba374e17a83c48817ed026c2",
            "af8a67cd3b52467499a5cb59eeab005e",
            "f9a83fd29d7f477a8c4b597a8c274d95",
            "c663c2983855429a814ee1fab1060a84",
            "42d5571886a5494fb941aebdf717f9eb",
            "9dd025e7c04a4738bf89ceeecfcf7b83",
            "fe105203e1764a43abf3b586cca0ba80",
            "c69a31df6f6649f68780a89580951acb"
          ]
        },
        "id": "A1O2QTjBs7G1",
        "outputId": "112fa42a-75ca-49a6-d7c8-e98b0a784f69"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2a3dd631d444cabaeb708cd41b84d8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a42e5794da24ed2840edb61b06d899e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.41M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef5b6d82c5f34efbbe49dfde52406515"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/732 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e55ff3dfb4a4ba5b08294aca52e175c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/712 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1b7d3a2218941f6b338ee4c251c339c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/117M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "add29a12ba6446e89189e9a01de65be8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# пути к файлам\n",
        "train_file_path = '/content/drive/MyDrive/biv hack/for-teams/train_dataset.csv'\n",
        "test_file_path = '/content/drive/MyDrive/biv hack/for-teams/payments_training.tsv'\n"
      ],
      "metadata": {
        "id": "NkzxE2jxvmU5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка обучающих данных\n",
        "train = load_data(train_file_path, sep=',', header=0, names=['ID', 'Content', 'reasoning', 'TARGET', 'Date', 'Price', 'Fold'])\n",
        "train = train[['Content', 'Date', 'TARGET', 'Price']]\n",
        "\n",
        "# Загрузка тестовых данных\n",
        "test = load_data(test_file_path, sep='\\t', header=None, names=['ID', 'Date', 'Price', 'Content', 'TARGET'])\n",
        "test = test[['Content', 'Date', 'TARGET', 'Price']]\n",
        "\n",
        "# Инициализация progress_apply\n",
        "tqdm.pandas()\n",
        "\n",
        "# Извлечение признаков из обучающих и тестовых данных\n",
        "train = extract_features(train, 'Content')\n",
        "test = extract_features(test, 'Content')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4LURDARtN9r",
        "outputId": "58976921-790f-498b-bad1-83c66a80b289"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5970/5970 [01:08<00:00, 87.00it/s] \n",
            "100%|██████████| 500/500 [00:07<00:00, 63.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_train = pd.concat([train, test], ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "D98tHbBOxWc4",
        "outputId": "b7cd467f-20bb-4851-c957-a142f3234bd6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Date        TARGET      Price  date_difference  \\\n",
              "0    2024-11-07       SERVICE    32600.0             76.0   \n",
              "1    2024-11-07       SERVICE    30900.0           -121.0   \n",
              "2    2024-11-07    FOOD_GOODS     4210.0              NaN   \n",
              "3    2024-11-07           TAX     4630.0              NaN   \n",
              "4    2024-11-07       SERVICE     8000.0            316.0   \n",
              "...         ...           ...        ...              ...   \n",
              "6465 2024-11-07           TAX     2610.0              NaN   \n",
              "6466 2024-11-07  BANK_SERVICE    31200.0              NaN   \n",
              "6467 2024-11-07       SERVICE    18200.0            197.0   \n",
              "6468 2024-11-07    FOOD_GOODS  2870000.0              NaN   \n",
              "6469 2024-11-07       SERVICE     2210.0              NaN   \n",
              "\n",
              "      has_contract_number  word_count  embedding_0  embedding_1  embedding_2  \\\n",
              "0                   False           8    -0.014197    -0.113569    -0.311699   \n",
              "1                   False           6    -0.268744    -0.247321     0.181615   \n",
              "2                   False          14     0.404704     0.311802     0.141604   \n",
              "3                   False           2    -0.004122     0.046135    -0.452642   \n",
              "4                   False           7    -0.482871    -0.159998     0.082481   \n",
              "...                   ...         ...          ...          ...          ...   \n",
              "6465                False           2     0.107667     0.274753    -0.246876   \n",
              "6466                False          15    -0.277803     0.602821    -0.585012   \n",
              "6467                False           7     0.053888     0.204427    -0.376022   \n",
              "6468                False          19     0.116363     0.089819    -0.153850   \n",
              "6469                False           3    -0.112120     0.515678     0.150660   \n",
              "\n",
              "      embedding_3  ...  coleman_liau_index  automated_readability_index  \\\n",
              "0       -0.756214  ...                8.66                          7.9   \n",
              "1       -0.624568  ...                9.15                          9.8   \n",
              "2       -0.036590  ...               16.54                         12.7   \n",
              "3       -0.301388  ...               33.20                         31.4   \n",
              "4       -0.421207  ...                6.56                          7.0   \n",
              "...           ...  ...                 ...                          ...   \n",
              "6465    -0.057394  ...                7.10                         10.2   \n",
              "6466    -0.808449  ...               21.57                         18.1   \n",
              "6467    -0.771425  ...                9.87                          9.7   \n",
              "6468    -0.324475  ...                6.43                          8.2   \n",
              "6469    -0.207508  ...               18.92                         16.2   \n",
              "\n",
              "      dale_chall_readability_score  difficult_words  linsear_write_formula  \\\n",
              "0                            19.82                0                    3.0   \n",
              "1                            22.36                0                    2.0   \n",
              "2                            23.16                0                    2.5   \n",
              "3                            19.53                0                    0.0   \n",
              "4                            19.77                0                    2.5   \n",
              "...                            ...              ...                    ...   \n",
              "6465                         19.53                0                    0.0   \n",
              "6466                         20.17                0                    6.5   \n",
              "6467                         22.03                0                    2.5   \n",
              "6468                         22.94                0                    0.9   \n",
              "6469                         19.58                0                    0.5   \n",
              "\n",
              "      gunning_fog  text_standard  syllable_count  lexicon_count  \\\n",
              "0            3.20            0.0               8              8   \n",
              "1            2.40           10.0               6              6   \n",
              "2            2.80            3.0              14             14   \n",
              "3            0.80            0.0               2              2   \n",
              "4            2.80            7.0               7              7   \n",
              "...           ...            ...             ...            ...   \n",
              "6465         0.80            0.0               2              2   \n",
              "6466         6.00            0.0              15             15   \n",
              "6467         2.80           10.0               7              7   \n",
              "6468         1.52           23.0              19             19   \n",
              "6469         1.20            1.0               3              3   \n",
              "\n",
              "      sentence_count  \n",
              "0                  1  \n",
              "1                  1  \n",
              "2                  2  \n",
              "3                  1  \n",
              "4                  1  \n",
              "...              ...  \n",
              "6465               1  \n",
              "6466               1  \n",
              "6467               1  \n",
              "6468               5  \n",
              "6469               1  \n",
              "\n",
              "[6470 rows x 331 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af028025-a9c8-41a2-96e5-94742a12b0a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>TARGET</th>\n",
              "      <th>Price</th>\n",
              "      <th>date_difference</th>\n",
              "      <th>has_contract_number</th>\n",
              "      <th>word_count</th>\n",
              "      <th>embedding_0</th>\n",
              "      <th>embedding_1</th>\n",
              "      <th>embedding_2</th>\n",
              "      <th>embedding_3</th>\n",
              "      <th>...</th>\n",
              "      <th>coleman_liau_index</th>\n",
              "      <th>automated_readability_index</th>\n",
              "      <th>dale_chall_readability_score</th>\n",
              "      <th>difficult_words</th>\n",
              "      <th>linsear_write_formula</th>\n",
              "      <th>gunning_fog</th>\n",
              "      <th>text_standard</th>\n",
              "      <th>syllable_count</th>\n",
              "      <th>lexicon_count</th>\n",
              "      <th>sentence_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-11-07</td>\n",
              "      <td>SERVICE</td>\n",
              "      <td>32600.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>False</td>\n",
              "      <td>8</td>\n",
              "      <td>-0.014197</td>\n",
              "      <td>-0.113569</td>\n",
              "      <td>-0.311699</td>\n",
              "      <td>-0.756214</td>\n",
              "      <td>...</td>\n",
              "      <td>8.66</td>\n",
              "      <td>7.9</td>\n",
              "      <td>19.82</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-11-07</td>\n",
              "      <td>SERVICE</td>\n",
              "      <td>30900.0</td>\n",
              "      <td>-121.0</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.268744</td>\n",
              "      <td>-0.247321</td>\n",
              "      <td>0.181615</td>\n",
              "      <td>-0.624568</td>\n",
              "      <td>...</td>\n",
              "      <td>9.15</td>\n",
              "      <td>9.8</td>\n",
              "      <td>22.36</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.40</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-11-07</td>\n",
              "      <td>FOOD_GOODS</td>\n",
              "      <td>4210.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>14</td>\n",
              "      <td>0.404704</td>\n",
              "      <td>0.311802</td>\n",
              "      <td>0.141604</td>\n",
              "      <td>-0.036590</td>\n",
              "      <td>...</td>\n",
              "      <td>16.54</td>\n",
              "      <td>12.7</td>\n",
              "      <td>23.16</td>\n",
              "      <td>0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-11-07</td>\n",
              "      <td>TAX</td>\n",
              "      <td>4630.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.004122</td>\n",
              "      <td>0.046135</td>\n",
              "      <td>-0.452642</td>\n",
              "      <td>-0.301388</td>\n",
              "      <td>...</td>\n",
              "      <td>33.20</td>\n",
              "      <td>31.4</td>\n",
              "      <td>19.53</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-11-07</td>\n",
              "      <td>SERVICE</td>\n",
              "      <td>8000.0</td>\n",
              "      <td>316.0</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "      <td>-0.482871</td>\n",
              "      <td>-0.159998</td>\n",
              "      <td>0.082481</td>\n",
              "      <td>-0.421207</td>\n",
              "      <td>...</td>\n",
              "      <td>6.56</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.77</td>\n",
              "      <td>0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.80</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6465</th>\n",
              "      <td>2024-11-07</td>\n",
              "      <td>TAX</td>\n",
              "      <td>2610.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>0.107667</td>\n",
              "      <td>0.274753</td>\n",
              "      <td>-0.246876</td>\n",
              "      <td>-0.057394</td>\n",
              "      <td>...</td>\n",
              "      <td>7.10</td>\n",
              "      <td>10.2</td>\n",
              "      <td>19.53</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6466</th>\n",
              "      <td>2024-11-07</td>\n",
              "      <td>BANK_SERVICE</td>\n",
              "      <td>31200.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>15</td>\n",
              "      <td>-0.277803</td>\n",
              "      <td>0.602821</td>\n",
              "      <td>-0.585012</td>\n",
              "      <td>-0.808449</td>\n",
              "      <td>...</td>\n",
              "      <td>21.57</td>\n",
              "      <td>18.1</td>\n",
              "      <td>20.17</td>\n",
              "      <td>0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>6.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6467</th>\n",
              "      <td>2024-11-07</td>\n",
              "      <td>SERVICE</td>\n",
              "      <td>18200.0</td>\n",
              "      <td>197.0</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "      <td>0.053888</td>\n",
              "      <td>0.204427</td>\n",
              "      <td>-0.376022</td>\n",
              "      <td>-0.771425</td>\n",
              "      <td>...</td>\n",
              "      <td>9.87</td>\n",
              "      <td>9.7</td>\n",
              "      <td>22.03</td>\n",
              "      <td>0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.80</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6468</th>\n",
              "      <td>2024-11-07</td>\n",
              "      <td>FOOD_GOODS</td>\n",
              "      <td>2870000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>19</td>\n",
              "      <td>0.116363</td>\n",
              "      <td>0.089819</td>\n",
              "      <td>-0.153850</td>\n",
              "      <td>-0.324475</td>\n",
              "      <td>...</td>\n",
              "      <td>6.43</td>\n",
              "      <td>8.2</td>\n",
              "      <td>22.94</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.52</td>\n",
              "      <td>23.0</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6469</th>\n",
              "      <td>2024-11-07</td>\n",
              "      <td>SERVICE</td>\n",
              "      <td>2210.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.112120</td>\n",
              "      <td>0.515678</td>\n",
              "      <td>0.150660</td>\n",
              "      <td>-0.207508</td>\n",
              "      <td>...</td>\n",
              "      <td>18.92</td>\n",
              "      <td>16.2</td>\n",
              "      <td>19.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6470 rows × 331 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af028025-a9c8-41a2-96e5-94742a12b0a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-af028025-a9c8-41a2-96e5-94742a12b0a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-af028025-a9c8-41a2-96e5-94742a12b0a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b4b5d1eb-478f-48d3-893d-c0c93f3f4628\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4b5d1eb-478f-48d3-893d-c0c93f3f4628')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b4b5d1eb-478f-48d3-893d-c0c93f3f4628 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "full_train"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_THREADS = 4\n",
        "N_FOLDS = 5\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "TIMEOUT = 3600\n",
        "TARGET_NAME = 'TARGET'"
      ],
      "metadata": {
        "id": "6k1WsuBVUQxj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(RANDOM_STATE)\n",
        "torch.set_num_threads(N_THREADS)"
      ],
      "metadata": {
        "id": "LTNZ60RUUQuS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = Task('multiclass', metric='auc_mu')"
      ],
      "metadata": {
        "id": "JamHPL0wXzP_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roles = {\n",
        "    'target': TARGET_NAME,\n",
        "    'drop': ['Date']\n",
        "}"
      ],
      "metadata": {
        "id": "QgnyaDsOXzGS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "automl = TabularUtilizedAutoML(\n",
        "    task = task,\n",
        "    timeout = TIMEOUT,\n",
        "    cpu_limit = N_THREADS,\n",
        "    reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
        ")"
      ],
      "metadata": {
        "id": "frsIE-rJxvDb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_of_fold_predictions = automl.fit_predict(full_train, roles = roles, verbose = 1)"
      ],
      "metadata": {
        "id": "uJ2rzJ9iYtnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f74198-ad20-4776-e938-9a54368188cf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] - time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:- time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] - CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:- CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:\u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] ==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] Start 0 automl preset configuration:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:Start 0 automl preset configuration:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:\u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
            "INFO3:lightautoml.addons.utilization.utilization:Found reader_params in kwargs, need to combine\n",
            "INFO3:lightautoml.addons.utilization.utilization:Merged variant for reader_params = {'n_jobs': 4, 'cv': 5, 'random_state': 42}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] Task: multiclass\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: multiclass\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] - time: 3599.99 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 3599.99 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] - CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:03] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:04] \u001b[1mTrain data shape: (6470, 331)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (6470, 331)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:31] Layer \u001b[1m1\u001b[0m train process start. Time left 3572.98 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 3572.98 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:23:35] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519], 'embed_sizes': array([177, 315, 192,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  54,  86,  66,  27,\n",
            "        50,  27,  24,  27,   6,  65,  65,  66,  37,  70,  60,  74, 116,\n",
            "       108,  70], dtype=int32), 'data_size': 520}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.992757896970924\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.9990253889084423\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.9995241389270133\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.999860638985336\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.9999155779559857\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.9999800695676988\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.9999868878734861\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.9999889858137284\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.999989510298789\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.9999874123585467\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.9999874123585467\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.9940393895142406\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.9987861865335018\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.9991885878106104\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.9996456795556554\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.9997685638310345\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.9999028470552187\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.9999269580188418\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.9999382072384363\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.9999484009183547\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.999943038596813\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.999943038596813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:26:53] Time limit exceeded after calculating fold 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:26:53] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.9999686556128986\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.9999686556128986\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:26:53] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:26:53] Time left 3370.85 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 3370.85 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:26:54] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 32, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.5, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.405473\tvalid's Opt metric: 0.999796\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.143938\tvalid's Opt metric: 0.999886\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.0744557\tvalid's Opt metric: 0.999926\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.050844\tvalid's Opt metric: 0.999936\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.0407843\tvalid's Opt metric: 0.999947\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.0357101\tvalid's Opt metric: 0.999951\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.0331098\tvalid's Opt metric: 0.99996\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.0316257\tvalid's Opt metric: 0.999962\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.0307029\tvalid's Opt metric: 0.999964\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.0301653\tvalid's Opt metric: 0.999965\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.029898\tvalid's Opt metric: 0.999966\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.0297379\tvalid's Opt metric: 0.999967\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's multi_logloss: 0.0297039\tvalid's Opt metric: 0.999966\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1124]\tvalid's multi_logloss: 0.0298335\tvalid's Opt metric: 0.999967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:30:50] Time limit exceeded after calculating fold 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:30:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9999674819262452\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9999674819262452\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:30:50] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:30:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9420114\tbest: 0.9420114 (0)\ttotal: 149ms\tremaining: 7m 25s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9989178\tbest: 0.9989191 (99)\ttotal: 10.3s\tremaining: 4m 55s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9996832\tbest: 0.9996832 (200)\ttotal: 18s\tremaining: 4m 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9998141\tbest: 0.9998151 (299)\ttotal: 29.9s\tremaining: 4m 27s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9998709\tbest: 0.9998709 (399)\ttotal: 39.2s\tremaining: 4m 14s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998954\tbest: 0.9999019 (476)\ttotal: 46s\tremaining: 3m 49s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9999113\tbest: 0.9999124 (566)\ttotal: 55.1s\tremaining: 3m 39s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9999218\tbest: 0.9999218 (695)\ttotal: 1m 1s\tremaining: 3m 23s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9999366\tbest: 0.9999393 (783)\ttotal: 1m 11s\tremaining: 3m 15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9999466\tbest: 0.9999482 (894)\ttotal: 1m 18s\tremaining: 3m 3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9999503\tbest: 0.9999562 (992)\ttotal: 1m 27s\tremaining: 2m 55s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9999567\tbest: 0.9999572 (1090)\ttotal: 1m 36s\tremaining: 2m 46s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.9999593\tbest: 0.9999593 (1171)\ttotal: 1m 43s\tremaining: 2m 35s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999593413\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1171\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1172 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9430462\tbest: 0.9430462 (0)\ttotal: 175ms\tremaining: 8m 45s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9988952\tbest: 0.9988973 (99)\ttotal: 9.19s\tremaining: 4m 23s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9995455\tbest: 0.9995455 (200)\ttotal: 18.9s\tremaining: 4m 22s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9997517\tbest: 0.9997517 (300)\ttotal: 26.2s\tremaining: 3m 55s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9998322\tbest: 0.9998337 (397)\ttotal: 35.6s\tremaining: 3m 50s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998547\tbest: 0.9998553 (499)\ttotal: 42.6s\tremaining: 3m 32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998701\tbest: 0.9998785 (564)\ttotal: 52s\tremaining: 3m 27s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9998859\tbest: 0.9998890 (684)\ttotal: 59.7s\tremaining: 3m 15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9998911\tbest: 0.9998953 (770)\ttotal: 1m 8s\tremaining: 3m 8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9998963\tbest: 0.9999005 (866)\ttotal: 1m 17s\tremaining: 3m\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9999047\tbest: 0.9999053 (997)\ttotal: 1m 25s\tremaining: 2m 50s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9999100\tbest: 0.9999100 (1097)\ttotal: 1m 34s\tremaining: 2m 43s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.9999194\tbest: 0.9999200 (1199)\ttotal: 1m 42s\tremaining: 2m 32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.9999221\tbest: 0.9999237 (1251)\ttotal: 1m 51s\tremaining: 2m 25s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999236625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1251\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1252 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9392924\tbest: 0.9392924 (0)\ttotal: 101ms\tremaining: 5m 3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9991940\tbest: 0.9991945 (99)\ttotal: 10.4s\tremaining: 4m 59s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9996390\tbest: 0.9996390 (200)\ttotal: 17.9s\tremaining: 4m 9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9997385\tbest: 0.9997392 (286)\ttotal: 27.7s\tremaining: 4m 8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9997845\tbest: 0.9997877 (398)\ttotal: 35.3s\tremaining: 3m 48s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998174\tbest: 0.9998236 (483)\ttotal: 44.4s\tremaining: 3m 41s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998285\tbest: 0.9998301 (598)\ttotal: 52.9s\tremaining: 3m 31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9998440\tbest: 0.9998440 (700)\ttotal: 1m\tremaining: 3m 19s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9998540\tbest: 0.9998551 (793)\ttotal: 1m 10s\tremaining: 3m 13s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9998568\tbest: 0.9998568 (899)\ttotal: 1m 17s\tremaining: 3m\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9998621\tbest: 0.9998637 (999)\ttotal: 1m 27s\tremaining: 2m 54s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9998616\tbest: 0.9998647 (1060)\ttotal: 1m 34s\tremaining: 2m 42s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9998647449\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1060\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1061 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9489340\tbest: 0.9489340 (0)\ttotal: 104ms\tremaining: 5m 12s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9993370\tbest: 0.9993433 (99)\ttotal: 8.06s\tremaining: 3m 51s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9997617\tbest: 0.9997617 (200)\ttotal: 18s\tremaining: 4m 11s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9998831\tbest: 0.9998831 (300)\ttotal: 26s\tremaining: 3m 53s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9999227\tbest: 0.9999233 (394)\ttotal: 35.5s\tremaining: 3m 50s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9999333\tbest: 0.9999360 (488)\ttotal: 44.7s\tremaining: 3m 42s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9999407\tbest: 0.9999418 (571)\ttotal: 52.1s\tremaining: 3m 28s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999417879\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 571\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 572 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9375611\tbest: 0.9375611 (0)\ttotal: 198ms\tremaining: 9m 53s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9990069\tbest: 0.9990069 (100)\ttotal: 8.73s\tremaining: 4m 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9996711\tbest: 0.9996711 (200)\ttotal: 18.6s\tremaining: 4m 19s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9998624\tbest: 0.9998624 (299)\ttotal: 25.9s\tremaining: 3m 51s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9999060\tbest: 0.9999076 (386)\ttotal: 35.4s\tremaining: 3m 49s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9999383\tbest: 0.9999442 (481)\ttotal: 42.5s\tremaining: 3m 32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9999472\tbest: 0.9999472 (600)\ttotal: 51.8s\tremaining: 3m 26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9999589\tbest: 0.9999595 (699)\ttotal: 1m\tremaining: 3m 17s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9999668\tbest: 0.9999674 (799)\ttotal: 1m 8s\tremaining: 3m 7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9999705\tbest: 0.9999705 (900)\ttotal: 1m 17s\tremaining: 3m 1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9999695\tbest: 0.9999726 (976)\ttotal: 1m 25s\tremaining: 2m 49s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999726327\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 976\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 977 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:38:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.9998929318521557\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.9998929318521557\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:38:51] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:38:51] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 131.67 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 131.67 secs\n",
            "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-c9bf9d50-243b-4c84-9933-2346d6e366ad\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9127349\tbest: 0.9127349 (0)\ttotal: 72.1ms\tremaining: 3m 36s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9984723\tbest: 0.9984723 (100)\ttotal: 5.48s\tremaining: 2m 37s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9994257\tbest: 0.9994257 (200)\ttotal: 11.5s\tremaining: 2m 40s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9997145\tbest: 0.9997145 (300)\ttotal: 18.3s\tremaining: 2m 44s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9998243\tbest: 0.9998243 (400)\ttotal: 23.1s\tremaining: 2m 30s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998594\tbest: 0.9998594 (499)\ttotal: 30.4s\tremaining: 2m 31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998814\tbest: 0.9998852 (597)\ttotal: 35.1s\tremaining: 2m 20s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9999062\tbest: 0.9999062 (700)\ttotal: 39.9s\tremaining: 2m 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9999163\tbest: 0.9999168 (788)\ttotal: 47.2s\tremaining: 2m 9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9999347\tbest: 0.9999347 (899)\ttotal: 52s\tremaining: 2m 1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9999415\tbest: 0.9999426 (996)\ttotal: 57.9s\tremaining: 1m 55s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9999505\tbest: 0.9999516 (1095)\ttotal: 1m 3s\tremaining: 1m 50s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.9999531\tbest: 0.9999531 (1190)\ttotal: 1m 8s\tremaining: 1m 43s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.9999552\tbest: 0.9999552 (1257)\ttotal: 1m 16s\tremaining: 1m 39s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999552235\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1257\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1258 iterations.\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.9999462292006218 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.9999462292006218.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.9999462292006218 in 0:01:19.781340\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8939803\tbest: 0.8939803 (0)\ttotal: 50ms\tremaining: 2m 29s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9975817\tbest: 0.9975817 (100)\ttotal: 3.92s\tremaining: 1m 52s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9989136\tbest: 0.9989136 (200)\ttotal: 8.79s\tremaining: 2m 2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9995206\tbest: 0.9995206 (300)\ttotal: 13.8s\tremaining: 2m 3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9996965\tbest: 0.9996976 (399)\ttotal: 17.3s\tremaining: 1m 52s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998009\tbest: 0.9998009 (497)\ttotal: 21s\tremaining: 1m 44s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998542\tbest: 0.9998542 (599)\ttotal: 26.6s\tremaining: 1m 46s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9998774\tbest: 0.9998790 (690)\ttotal: 30.2s\tremaining: 1m 38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9999064\tbest: 0.9999064 (800)\ttotal: 33.6s\tremaining: 1m 32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9999132\tbest: 0.9999143 (861)\ttotal: 38.1s\tremaining: 1m 28s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9999243\tbest: 0.9999258 (945)\ttotal: 43s\tremaining: 1m 25s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9999300\tbest: 0.9999300 (1100)\ttotal: 46.5s\tremaining: 1m 20s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.9999332\tbest: 0.9999358 (1197)\ttotal: 50s\tremaining: 1m 14s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.9999353\tbest: 0.9999369 (1253)\ttotal: 55.7s\tremaining: 1m 12s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.9999437\tbest: 0.9999437 (1399)\ttotal: 59.6s\tremaining: 1m 7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.9999469\tbest: 0.9999490 (1489)\ttotal: 1m 3s\tremaining: 1m 3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.9999490\tbest: 0.9999505 (1526)\ttotal: 1m 6s\tremaining: 58.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999505353\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1526\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1527 iterations.\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.9999290105927726 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 0 with value: 0.9999462292006218.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.9999290105927726 in 0:01:09.232309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:41:20] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}\u001b[0m\n",
            " achieve 0.9999 auc_mu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:41:20] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.0024430162614261413, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 4, 'min_data_in_leaf': 4, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Max', 'verbose': 100, 'allow_writing_files': False}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9127349\tbest: 0.9127349 (0)\ttotal: 134ms\tremaining: 6m 42s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9984723\tbest: 0.9984723 (100)\ttotal: 6.69s\tremaining: 3m 12s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9994257\tbest: 0.9994257 (200)\ttotal: 11.9s\tremaining: 2m 45s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9997145\tbest: 0.9997145 (300)\ttotal: 19.5s\tremaining: 2m 54s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9998243\tbest: 0.9998243 (400)\ttotal: 24.5s\tremaining: 2m 38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998594\tbest: 0.9998594 (499)\ttotal: 30.7s\tremaining: 2m 32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998814\tbest: 0.9998852 (597)\ttotal: 36.7s\tremaining: 2m 26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9999062\tbest: 0.9999062 (700)\ttotal: 41.6s\tremaining: 2m 16s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9999163\tbest: 0.9999168 (788)\ttotal: 49s\tremaining: 2m 14s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9999347\tbest: 0.9999347 (899)\ttotal: 53.8s\tremaining: 2m 5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9999415\tbest: 0.9999426 (996)\ttotal: 58.7s\tremaining: 1m 57s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9999505\tbest: 0.9999516 (1095)\ttotal: 1m 5s\tremaining: 1m 53s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.9999531\tbest: 0.9999531 (1190)\ttotal: 1m 10s\tremaining: 1m 46s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.9999552\tbest: 0.9999552 (1257)\ttotal: 1m 17s\tremaining: 1m 40s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999552235\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1257\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1258 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9108342\tbest: 0.9108342 (0)\ttotal: 70.9ms\tremaining: 3m 32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9980986\tbest: 0.9980986 (100)\ttotal: 5.47s\tremaining: 2m 37s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9991475\tbest: 0.9991548 (198)\ttotal: 13s\tremaining: 3m 1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9995145\tbest: 0.9995145 (300)\ttotal: 18s\tremaining: 2m 41s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9996617\tbest: 0.9996617 (400)\ttotal: 23s\tremaining: 2m 29s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9997516\tbest: 0.9997569 (499)\ttotal: 30.3s\tremaining: 2m 30s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998032\tbest: 0.9998043 (599)\ttotal: 35.1s\tremaining: 2m 20s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9998353\tbest: 0.9998364 (692)\ttotal: 41.4s\tremaining: 2m 15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9998527\tbest: 0.9998538 (798)\ttotal: 46.9s\tremaining: 2m 8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9998701\tbest: 0.9998711 (893)\ttotal: 51.6s\tremaining: 2m\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9998764\tbest: 0.9998785 (994)\ttotal: 58.9s\tremaining: 1m 57s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9998848\tbest: 0.9998858 (1056)\ttotal: 1m 3s\tremaining: 1m 49s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.9998974\tbest: 0.9998984 (1185)\ttotal: 1m 8s\tremaining: 1m 43s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.9999073\tbest: 0.9999073 (1300)\ttotal: 1m 15s\tremaining: 1m 39s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.9999068\tbest: 0.9999105 (1388)\ttotal: 1m 20s\tremaining: 1m 32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.9999105\tbest: 0.9999121 (1475)\ttotal: 1m 27s\tremaining: 1m 27s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.9999174\tbest: 0.9999184 (1567)\ttotal: 1m 33s\tremaining: 1m 21s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.9999153\tbest: 0.9999189 (1665)\ttotal: 1m 37s\tremaining: 1m 14s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.9999194\tbest: 0.9999200 (1752)\ttotal: 1m 45s\tremaining: 1m 9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.9999210\tbest: 0.9999231 (1829)\ttotal: 1m 49s\tremaining: 1m 3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\ttest: 0.9999273\tbest: 0.9999289 (1985)\ttotal: 1m 55s\tremaining: 57.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\ttest: 0.9999263\tbest: 0.9999294 (2070)\ttotal: 2m 2s\tremaining: 52.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999294351\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2070\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2071 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9171459\tbest: 0.9171459 (0)\ttotal: 76.2ms\tremaining: 3m 48s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9988733\tbest: 0.9988733 (100)\ttotal: 8.1s\tremaining: 3m 52s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9995128\tbest: 0.9995128 (200)\ttotal: 13.3s\tremaining: 3m 4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9996684\tbest: 0.9996691 (299)\ttotal: 18.4s\tremaining: 2m 45s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9997374\tbest: 0.9997386 (385)\ttotal: 25.6s\tremaining: 2m 46s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9997779\tbest: 0.9997779 (500)\ttotal: 30.5s\tremaining: 2m 32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9997922\tbest: 0.9997922 (600)\ttotal: 37.1s\tremaining: 2m 28s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9997977\tbest: 0.9998035 (689)\ttotal: 42.6s\tremaining: 2m 19s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9998089\tbest: 0.9998110 (764)\ttotal: 47.5s\tremaining: 2m 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9998147\tbest: 0.9998178 (881)\ttotal: 54.8s\tremaining: 2m 7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9998197\tbest: 0.9998208 (942)\ttotal: 59.5s\tremaining: 1m 58s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9998262\tbest: 0.9998262 (1094)\ttotal: 1m 4s\tremaining: 1m 51s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.9998305\tbest: 0.9998326 (1174)\ttotal: 1m 11s\tremaining: 1m 47s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.9998336\tbest: 0.9998352 (1260)\ttotal: 1m 16s\tremaining: 1m 39s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.9998368\tbest: 0.9998384 (1391)\ttotal: 1m 23s\tremaining: 1m 34s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.9998431\tbest: 0.9998431 (1491)\ttotal: 1m 28s\tremaining: 1m 28s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.9998368\tbest: 0.9998496 (1557)\ttotal: 1m 33s\tremaining: 1m 21s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9998496439\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1557\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1558 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9281463\tbest: 0.9281463 (0)\ttotal: 137ms\tremaining: 6m 52s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9988171\tbest: 0.9988171 (100)\ttotal: 5.81s\tremaining: 2m 46s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9995035\tbest: 0.9995035 (200)\ttotal: 11.2s\tremaining: 2m 35s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9998075\tbest: 0.9998075 (300)\ttotal: 18.5s\tremaining: 2m 45s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9998916\tbest: 0.9998916 (393)\ttotal: 23.4s\tremaining: 2m 31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9999209\tbest: 0.9999220 (496)\ttotal: 30.2s\tremaining: 2m 30s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9999296\tbest: 0.9999312 (575)\ttotal: 35.5s\tremaining: 2m 21s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9999349\tbest: 0.9999360 (690)\ttotal: 40.4s\tremaining: 2m 12s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9999428\tbest: 0.9999428 (783)\ttotal: 47.7s\tremaining: 2m 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9999487\tbest: 0.9999492 (894)\ttotal: 52.5s\tremaining: 2m 2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9999476\tbest: 0.9999503 (907)\ttotal: 57.8s\tremaining: 1m 55s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999502551\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 907\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 908 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9142831\tbest: 0.9142831 (0)\ttotal: 141ms\tremaining: 7m 3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9984437\tbest: 0.9984437 (100)\ttotal: 6.9s\tremaining: 3m 18s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9993707\tbest: 0.9993717 (199)\ttotal: 12.1s\tremaining: 2m 48s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9997564\tbest: 0.9997564 (300)\ttotal: 19.7s\tremaining: 2m 56s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9998540\tbest: 0.9998592 (398)\ttotal: 24.6s\tremaining: 2m 39s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998944\tbest: 0.9998949 (499)\ttotal: 30.5s\tremaining: 2m 31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9999128\tbest: 0.9999128 (597)\ttotal: 36.6s\tremaining: 2m 26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9999500\tbest: 0.9999511 (692)\ttotal: 41.5s\tremaining: 2m 16s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9999521\tbest: 0.9999521 (756)\ttotal: 48.9s\tremaining: 2m 14s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9999626\tbest: 0.9999637 (878)\ttotal: 53.8s\tremaining: 2m 5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9999647\tbest: 0.9999658 (985)\ttotal: 58.6s\tremaining: 1m 57s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9999668\tbest: 0.9999679 (1079)\ttotal: 1m 5s\tremaining: 1m 53s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.9999684\tbest: 0.9999689 (1173)\ttotal: 1m 10s\tremaining: 1m 45s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.9999716\tbest: 0.9999721 (1297)\ttotal: 1m 16s\tremaining: 1m 40s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.9999716\tbest: 0.9999737 (1343)\ttotal: 1m 22s\tremaining: 1m 34s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999736853\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1343\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1344 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:48:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.9998910678315942\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.9998910678315942\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:48:51] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:48:51] Time left 2052.31 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 2052.31 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:48:51] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:48:51] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:48:51] Blending: optimization starts with equal weights and score \u001b[1m0.9999214439186962\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.9999214439186962\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:48:54] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9999643664645991\u001b[0m, weights = \u001b[1m[0.3497075  0.65029246 0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9999643664645991\u001b[0m, weights = \u001b[1m[0.3497075  0.65029246 0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:48:58] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9999683926479371\u001b[0m, weights = \u001b[1m[0.92367506 0.07632492 0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9999683926479371\u001b[0m, weights = \u001b[1m[0.92367506 0.07632492 0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.9999683926479371\u001b[0m, weights = \u001b[1m[0.92367506 0.07632492 0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.9999683926479371\u001b[0m, weights = \u001b[1m[0.92367506 0.07632492 0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] \u001b[1mAutoml preset training completed in 1558.41 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 1558.41 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.92368 * (2 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.07632 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.92368 * (2 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.07632 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] ==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] Start 1 automl preset configuration:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:Start 1 automl preset configuration:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:\u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n",
            "INFO3:lightautoml.addons.utilization.utilization:Found reader_params in kwargs, need to combine\n",
            "INFO3:lightautoml.addons.utilization.utilization:Merged variant for reader_params = {'n_jobs': 4, 'cv': 5, 'random_state': 43}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] Task: multiclass\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: multiclass\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] - time: 2041.46 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 2041.46 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] - CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:02] \u001b[1mTrain data shape: (6470, 331)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (6470, 331)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:26] Layer \u001b[1m1\u001b[0m train process start. Time left 2017.49 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 2017.49 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:49:28] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525], 'embed_sizes': array([177, 315, 192,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
            "        35,  35,  54,  86,  66,  27,  50,  27,  24,  27,   6,  65,  65,\n",
            "        66,  37,  70,  60,  74, 116, 108,  70], dtype=int32), 'data_size': 526}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.9928564615224901\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.9989216638002671\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.9993843654698426\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.9997806705855151\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.999839273467438\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.9999461901544504\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.9999525160865075\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.999958992533401\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.9999585782520136\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.9999431662991448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:51:14] Time limit exceeded after calculating fold 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:51:15] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.999958992533401\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.999958992533401\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:51:15] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:51:15] Time left 1908.88 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 1908.88 secs\n",
            "\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.404184\tvalid's Opt metric: 0.999597\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.147159\tvalid's Opt metric: 0.999792\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.0814334\tvalid's Opt metric: 0.99985\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.0590462\tvalid's Opt metric: 0.999875\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.0496246\tvalid's Opt metric: 0.99989\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.04453\tvalid's Opt metric: 0.999902\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.0418296\tvalid's Opt metric: 0.999912\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.0404346\tvalid's Opt metric: 0.999918\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.0394305\tvalid's Opt metric: 0.999921\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.038985\tvalid's Opt metric: 0.999925\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.0387037\tvalid's Opt metric: 0.999923\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.0385068\tvalid's Opt metric: 0.999925\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's multi_logloss: 0.0383741\tvalid's Opt metric: 0.999924\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1178]\tvalid's multi_logloss: 0.0385428\tvalid's Opt metric: 0.999925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:55:44] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:55:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 32, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.5, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.40865\tvalid's Opt metric: 0.999713\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.150874\tvalid's Opt metric: 0.999832\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.0830816\tvalid's Opt metric: 0.999879\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.0599767\tvalid's Opt metric: 0.999898\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.0500607\tvalid's Opt metric: 0.999908\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.0445523\tvalid's Opt metric: 0.999918\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.0421817\tvalid's Opt metric: 0.999924\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.0405954\tvalid's Opt metric: 0.999929\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.0395685\tvalid's Opt metric: 0.999931\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.0389871\tvalid's Opt metric: 0.999934\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.0386765\tvalid's Opt metric: 0.999937\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.0384996\tvalid's Opt metric: 0.999936\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1092]\tvalid's multi_logloss: 0.0386527\tvalid's Opt metric: 0.999938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:59:12] Time limit exceeded after calculating fold 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:59:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9999376379271946\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9999376379271946\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:59:12] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:59:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9288391\tbest: 0.9288391 (0)\ttotal: 107ms\tremaining: 5m 19s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9991463\tbest: 0.9991463 (100)\ttotal: 10.2s\tremaining: 4m 53s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9996703\tbest: 0.9996733 (199)\ttotal: 17.4s\tremaining: 4m 2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9998110\tbest: 0.9998121 (299)\ttotal: 27s\tremaining: 4m 1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9998506\tbest: 0.9998506 (400)\ttotal: 33.9s\tremaining: 3m 39s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998680\tbest: 0.9998695 (494)\ttotal: 43.1s\tremaining: 3m 35s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998749\tbest: 0.9998787 (573)\ttotal: 50s\tremaining: 3m 19s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9998844\tbest: 0.9998876 (637)\ttotal: 59.4s\tremaining: 3m 14s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.999887613\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 637\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 638 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9346799\tbest: 0.9346799 (0)\ttotal: 104ms\tremaining: 5m 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9991270\tbest: 0.9991334 (99)\ttotal: 10.4s\tremaining: 4m 58s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9996176\tbest: 0.9996264 (196)\ttotal: 17.8s\tremaining: 4m 7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9997872\tbest: 0.9997892 (294)\ttotal: 27.5s\tremaining: 4m 6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9998265\tbest: 0.9998265 (393)\ttotal: 35.7s\tremaining: 3m 51s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998517\tbest: 0.9998517 (494)\ttotal: 44s\tremaining: 3m 39s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998570\tbest: 0.9998596 (570)\ttotal: 53.3s\tremaining: 3m 32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9998654\tbest: 0.9998670 (696)\ttotal: 1m\tremaining: 3m 18s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9998742\tbest: 0.9998747 (784)\ttotal: 1m 9s\tremaining: 3m 11s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9998784\tbest: 0.9998795 (892)\ttotal: 1m 16s\tremaining: 2m 58s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9998821\tbest: 0.9998826 (970)\ttotal: 1m 26s\tremaining: 2m 52s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9998832\tbest: 0.9998853 (1084)\ttotal: 1m 33s\tremaining: 2m 40s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.9998890\tbest: 0.9998895 (1194)\ttotal: 1m 42s\tremaining: 2m 34s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.9998879\tbest: 0.9998911 (1259)\ttotal: 1m 50s\tremaining: 2m 24s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.9998926\tbest: 0.9998947 (1363)\ttotal: 1m 59s\tremaining: 2m 16s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.999894698\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1363\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1364 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9398315\tbest: 0.9398315 (0)\ttotal: 101ms\tremaining: 5m 2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9990308\tbest: 0.9990308 (100)\ttotal: 10.5s\tremaining: 5m\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9997408\tbest: 0.9997408 (200)\ttotal: 19.8s\tremaining: 4m 35s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9999268\tbest: 0.9999268 (300)\ttotal: 27.7s\tremaining: 4m 8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9999616\tbest: 0.9999621 (399)\ttotal: 37.2s\tremaining: 4m 1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9999774\tbest: 0.9999779 (481)\ttotal: 44.3s\tremaining: 3m 40s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9999810\tbest: 0.9999815 (567)\ttotal: 53.4s\tremaining: 3m 33s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9999831\tbest: 0.9999842 (673)\ttotal: 1m\tremaining: 3m 18s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9999863\tbest: 0.9999868 (776)\ttotal: 1m 9s\tremaining: 3m 11s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9999884\tbest: 0.9999889 (837)\ttotal: 1m 17s\tremaining: 2m 59s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9999916\tbest: 0.9999921 (998)\ttotal: 1m 26s\tremaining: 2m 52s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999920893\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 998\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 999 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:03:54] Time limit exceeded after calculating fold 2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:03:54] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.999903471376689\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.999903471376689\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:03:54] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:03:54] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
            "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-6daab39e-5567-4646-877d-8b72d052e3da\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8978760\tbest: 0.8978760 (0)\ttotal: 140ms\tremaining: 6m 59s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9987609\tbest: 0.9987609 (100)\ttotal: 6.51s\tremaining: 3m 6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9994449\tbest: 0.9994643 (197)\ttotal: 11.7s\tremaining: 2m 42s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9996842\tbest: 0.9996903 (297)\ttotal: 19.2s\tremaining: 2m 52s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9998058\tbest: 0.9998058 (400)\ttotal: 24.1s\tremaining: 2m 36s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998563\tbest: 0.9998584 (497)\ttotal: 30.3s\tremaining: 2m 31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998769\tbest: 0.9998774 (594)\ttotal: 36.4s\tremaining: 2m 25s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9998832\tbest: 0.9998832 (698)\ttotal: 41.2s\tremaining: 2m 15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9998927\tbest: 0.9998980 (788)\ttotal: 48.4s\tremaining: 2m 12s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9998959\tbest: 0.9998985 (867)\ttotal: 53.3s\tremaining: 2m 4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9998985234\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 867\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 868 iterations.\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.9998690143671068 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.9998690143671068.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.9998690143671068 in 0:00:57.407444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:04:51] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}\u001b[0m\n",
            " achieve 0.9999 auc_mu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:04:51] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.0024430162614261413, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 4, 'min_data_in_leaf': 4, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Max', 'verbose': 100, 'allow_writing_files': False}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8978760\tbest: 0.8978760 (0)\ttotal: 73ms\tremaining: 3m 38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9987609\tbest: 0.9987609 (100)\ttotal: 7.95s\tremaining: 3m 48s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9994449\tbest: 0.9994643 (197)\ttotal: 13.2s\tremaining: 3m 3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9996842\tbest: 0.9996903 (297)\ttotal: 20.1s\tremaining: 3m\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9998058\tbest: 0.9998058 (400)\ttotal: 25.7s\tremaining: 2m 46s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998563\tbest: 0.9998584 (497)\ttotal: 30.5s\tremaining: 2m 32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998769\tbest: 0.9998774 (594)\ttotal: 38s\tremaining: 2m 31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9998832\tbest: 0.9998832 (698)\ttotal: 42.9s\tremaining: 2m 20s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9998927\tbest: 0.9998980 (788)\ttotal: 48.4s\tremaining: 2m 12s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9998959\tbest: 0.9998985 (867)\ttotal: 55.2s\tremaining: 2m 8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9998985234\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 867\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 868 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9073706\tbest: 0.9073706 (0)\ttotal: 74.1ms\tremaining: 3m 42s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9985485\tbest: 0.9985600 (98)\ttotal: 7.39s\tremaining: 3m 32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9993801\tbest: 0.9993801 (200)\ttotal: 13s\tremaining: 3m\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9996233\tbest: 0.9996248 (299)\ttotal: 17.9s\tremaining: 2m 40s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9997267\tbest: 0.9997267 (400)\ttotal: 25.4s\tremaining: 2m 44s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9997958\tbest: 0.9997958 (500)\ttotal: 30.3s\tremaining: 2m 31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998243\tbest: 0.9998248 (589)\ttotal: 36.2s\tremaining: 2m 24s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9998476\tbest: 0.9998498 (692)\ttotal: 42.4s\tremaining: 2m 18s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9998618\tbest: 0.9998618 (794)\ttotal: 47.1s\tremaining: 2m 9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9998701\tbest: 0.9998722 (894)\ttotal: 54.4s\tremaining: 2m 6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9998801\tbest: 0.9998806 (992)\ttotal: 59.4s\tremaining: 1m 58s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9998827\tbest: 0.9998880 (1033)\ttotal: 1m 4s\tremaining: 1m 50s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9998879507\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1033\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1034 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9065550\tbest: 0.9065550 (0)\ttotal: 134ms\tremaining: 6m 41s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9985472\tbest: 0.9985472 (100)\ttotal: 6.22s\tremaining: 2m 58s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9995408\tbest: 0.9995408 (200)\ttotal: 11.3s\tremaining: 2m 37s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9997977\tbest: 0.9997977 (300)\ttotal: 18.8s\tremaining: 2m 48s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9999287\tbest: 0.9999292 (396)\ttotal: 23.7s\tremaining: 2m 33s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9999524\tbest: 0.9999529 (497)\ttotal: 30.3s\tremaining: 2m 31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9999664\tbest: 0.9999669 (599)\ttotal: 35.9s\tremaining: 2m 23s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9999743\tbest: 0.9999749 (689)\ttotal: 40.8s\tremaining: 2m 13s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9999759\tbest: 0.9999764 (790)\ttotal: 48.1s\tremaining: 2m 12s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9999780\tbest: 0.9999780 (833)\ttotal: 53s\tremaining: 2m 3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9999801\tbest: 0.9999817 (985)\ttotal: 57.9s\tremaining: 1m 55s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9999828\tbest: 0.9999828 (1074)\ttotal: 1m 5s\tremaining: 1m 52s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999827706\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1074\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1075 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9182839\tbest: 0.9182839 (0)\ttotal: 71.9ms\tremaining: 3m 35s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9982223\tbest: 0.9982223 (100)\ttotal: 7.09s\tremaining: 3m 23s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9992516\tbest: 0.9992521 (197)\ttotal: 13.3s\tremaining: 3m 4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9995716\tbest: 0.9995716 (300)\ttotal: 18.4s\tremaining: 2m 44s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9996954\tbest: 0.9996954 (400)\ttotal: 26s\tremaining: 2m 48s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9997638\tbest: 0.9997643 (494)\ttotal: 30.9s\tremaining: 2m 33s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9997969\tbest: 0.9997969 (599)\ttotal: 36.6s\tremaining: 2m 26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9998108\tbest: 0.9998134 (693)\ttotal: 43.1s\tremaining: 2m 21s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9998325\tbest: 0.9998325 (797)\ttotal: 47.9s\tremaining: 2m 11s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9998443\tbest: 0.9998453 (878)\ttotal: 55.2s\tremaining: 2m 8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9998593\tbest: 0.9998603 (997)\ttotal: 1m\tremaining: 1m 59s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.9998661\tbest: 0.9998661 (1100)\ttotal: 1m 4s\tremaining: 1m 51s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.9998663\tbest: 0.9998704 (1147)\ttotal: 1m 12s\tremaining: 1m 48s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9998703805\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1147\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1148 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.9262418\tbest: 0.9262418 (0)\ttotal: 76.1ms\tremaining: 3m 48s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9981976\tbest: 0.9981976 (100)\ttotal: 5.53s\tremaining: 2m 38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9992427\tbest: 0.9992427 (200)\ttotal: 13s\tremaining: 3m 1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9996798\tbest: 0.9996798 (300)\ttotal: 18.1s\tremaining: 2m 42s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9998070\tbest: 0.9998128 (396)\ttotal: 24.9s\tremaining: 2m 41s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.9998394\tbest: 0.9998401 (460)\ttotal: 30.4s\tremaining: 2m 31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.9998752\tbest: 0.9998774 (595)\ttotal: 35.1s\tremaining: 2m 20s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.9998918\tbest: 0.9998918 (695)\ttotal: 42.5s\tremaining: 2m 19s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9999072\tbest: 0.9999083 (793)\ttotal: 47.4s\tremaining: 2m 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9999124\tbest: 0.9999124 (899)\ttotal: 52.8s\tremaining: 2m 3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.9999176\tbest: 0.9999187 (987)\ttotal: 59.6s\tremaining: 1m 58s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9999186716\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 987\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 988 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.999873872636593\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.999873872636593\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:27] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:27] Time left 756.83 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 756.83 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:27] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:27] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:27] Blending: optimization starts with equal weights and score \u001b[1m0.9998976090442869\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.9998976090442869\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:30] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9999661329131817\u001b[0m, weights = \u001b[1m[0.41783333 0.5821666  0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9999661329131817\u001b[0m, weights = \u001b[1m[0.41783333 0.5821666  0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:33] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9999693315333398\u001b[0m, weights = \u001b[1m[0.48410362 0.5158964  0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9999693315333398\u001b[0m, weights = \u001b[1m[0.48410362 0.5158964  0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:36] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.9999693315333398\u001b[0m, weights = \u001b[1m[0.48410362 0.5158964  0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.9999693315333398\u001b[0m, weights = \u001b[1m[0.48410362 0.5158964  0.         0.        ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:36] Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:36] \u001b[1mAutoml preset training completed in 1294.19 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 1294.19 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:36] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.48410 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.51590 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.48410 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.51590 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:36] ==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.addons.utilization.utilization:==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:36] Blending: optimization starts with equal weights and score \u001b[1m0.999968955925877\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.999968955925877\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:38] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9999708472263775\u001b[0m, weights = \u001b[1m[0.76295125 0.23704872]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9999708472263775\u001b[0m, weights = \u001b[1m[0.76295125 0.23704872]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:39] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9999708472263775\u001b[0m, weights = \u001b[1m[0.76295125 0.23704872]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9999708472263775\u001b[0m, weights = \u001b[1m[0.76295125 0.23704872]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:10:39] Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = automl.predict(test)"
      ],
      "metadata": {
        "id": "uGp1Zf3YbWGD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = automl.outer_pipes[0].ml_algos[0].models[0][0].reader.class_mapping\n",
        "label_class = {ind:class_ for class_, ind in class_labels.items()}\n",
        "\n",
        "# Переводим вероятности в строковые значения классов\n",
        "predicted_indices = np.argmax(test_predictions.data, axis=1)\n",
        "predicted_classes = [label_class[idx] for idx in predicted_indices]"
      ],
      "metadata": {
        "id": "u3mSHiYYjOg3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score"
      ],
      "metadata": {
        "id": "sSeQYZlDk8jw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(test['TARGET'].values, predicted_classes, average='weighted')"
      ],
      "metadata": {
        "id": "CfG3NA33jOUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(test['TARGET'].values == predicted_classes)"
      ],
      "metadata": {
        "id": "d3fZcDYUlNIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Сохранение модели"
      ],
      "metadata": {
        "id": "4C0CLW1Vojuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('automl_model.pkl', 'wb') as f:\n",
        "    pickle.dump(automl, f)"
      ],
      "metadata": {
        "id": "xygNyrvHolsG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('automl_model.pkl', 'rb') as f:\n",
        "    loaded_automl = pickle.load(f)"
      ],
      "metadata": {
        "id": "HmxQkWhsomx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = loaded_automl.predict(test_final)"
      ],
      "metadata": {
        "id": "2rBNLgDbozSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = loaded_automl.reader.class_mapping\n",
        "label_class = {ind:class_ for class_, ind in class_labels.items()}\n",
        "\n",
        "# Переводим вероятности в строковые значения классов\n",
        "predicted_indices = np.argmax(test_predictions.data, axis=1)\n",
        "predicted_classes = [label_class[idx] for idx in predicted_indices]"
      ],
      "metadata": {
        "id": "3KtEUQX4ozOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hs516PY9ozGS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}